---
title: "Day 27"
title-slide-attributes:
  data-background-image: images/lake.jpg
  data-background-size: contain
  data-background-opacity: "0.5"
subtitle: "Math 216: Statistical Thinking"
author: "Bastola"
format:
  revealjs:
    html-math-method: mathjax
    mathjax-url: "https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/MathJax.js" 
    theme: [default, scss/main.scss]
    slide-number: true
    preview-links: auto
    history: true
    chalkboard: 
      src: drawings.json
    transition: slide
    background-transition: fade    
    touch: false
    controls: true
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
options(htmltools.preserve.raw = FALSE)
options(ggrepel.max.overlaps = Inf)


# load necessary packages
library(tidyverse)
library(countdown)
library(mosaic)
library(ggthemes)
library(forcats)
library(patchwork)
library(Lock5Data)
library(plotly)
library(nortest)
library(BSDA)
library(gridExtra)
# Set ggplot theme
theme_set(theme_tufte(base_size = 10))
yt <- 0
#<iframe width="1380" height="900" src="https://www.geogebra.org/m/mehn8u8s"></iframe>
#::: {.callout-note title="Definition"}
#<img src="images/Day23-1.png" style="display: block; margin: auto;" width="80%"  loading="lazy" decoding="async">
```


## Recap {.font70}

::: row
::: left

```{mermaid}
%%| echo: false
graph TD
  A[Start] --> B{"σ known?"}
  B -->|Yes| C["Use z-test/z-interval"]
  B -->|No| D{"n ≥ 30?"}
  D -->|Yes| E["CLT: Use t-test (z ≈ t)"]
  D -->|No| F["Normal? QQ-plot/test"]
  F -->|Yes| G[Use t-test]
  F -->|No| H[Non-parametric test]
```

:::

::: right

> With small samples (n < 30), normality checks become critical. Let’s examine real data from the `Davis` dataset (car package) of self-reported vs actual weights:

```{r}
#| echo: true
library(car)
data(Davis)
small_sample <- Davis$weight[1:15]  # Small subsample
ad.test(small_sample)$p.value 

```

:::
:::

## Challenges with Non-normal Distributions {.font70}

::: cle9

**What if the population data is decidedly non-normal?**

- **Small Sample Sizes and Non-normality**: When sample sizes are small ($n < 30$) and the data is non-normal, traditional tests like t-tests may become unreliable. This can lead to inflated **Type I errors**—incorrectly rejecting the null hypothesis ($H_0$) when it is true.

- **Nonparametric Statistics**: These tests do not assume a normal distribution. Instead, they rely on ranks or medians, making them robust to outliers and extreme values.
:::


## Visual Diagnostics: The Illusion of Normality (QQ plot) {.font70}

**Example**: 15-weight sample from `Davis` dataset:

```{r}
#| echo: true
qqPlot(small_sample, main="QQ-Plot: Small Sample") + theme_tufte()
```


## Visual Diagnostics: The Illusion of Normality (Histogram) {.font70}

**Example**: 15-weight sample from `Davis` dataset:

```{r}
#| echo: true
ggplot(tibble(x=small_sample), aes(x)) + 
  geom_histogram(fill="#1f77b4", bins=5) + 
  geom_vline(xintercept=57, color="red") +
  labs(title="Seemingly Normal? (n=15)")
```



## Case Study 1: Davis Weight Data (n=15) {.font80}

::: cle8
**Population Context**: Full dataset (N=200) has median=57kg, but our sample (first 15 obs) has median=68kg:

```{r}
#| echo: true
SIGN.test(small_sample, md=57)$p.value  
t.test(small_sample, mu=57)$p.value     
```

**Resolution**: Sign test detects true median shift (68 vs 57) while t-test is confused by:

- Right skew (γ₁ = 1.2)
- Outlier (166kg) inflating mean (64.1 vs median 68)
:::

## Case Study 2: Simulated Skewed Data (n=15) {.font80}

**Population**: Lognormal distribution (median=7.38, mean=12.18)

```{r}
#| echo: true
set.seed(123)
skewed_pop <- exp(rnorm(1000, mean=2))  # True median=7.38
samp <- sample(skewed_pop, 15)

# Wrong approach: t-test for median
t.test(samp, mu=7.38)$p.value    

# Right approach: Sign test
SIGN.test(samp, md=7.38)$p.value
```


## Type I Error Rates (10,000 Simulations) {.font80}

**When H₀ is TRUE** (testing median=7.38 in lognormal population):

```{r}
#| echo: true
set.seed(456)
err_rates <- replicate(10000, {
  samp <- sample(skewed_pop, 15)
  c(
    t = t.test(samp, mu = 7.38)$p.value < 0.05,
    sign = SIGN.test(samp, md = 7.38)$p.value < 0.05
  )
})

# Get one error rate per method:
rowMeans(err_rates)  
```

**Results**:

1. T-test falsely rejects 9.6% of time (inflated Type I error)
2. Sign test maintains 3.5% error rate


##  Recommendations {.font80}

::: cle6
1. **Small n**: Use sign test unless strong evidence of normality
2. **Visual Cues**:
   - Always pair histograms (≤5 bins) with QQ-plots
   - Treat "normal-looking" plots with skepticism
3. **Test Alignment**:
   - Means → t-test (requires normality)
   - Medians → sign test (requires only ranked data)
:::

## How P-values are Calculated: Sign Test {.font80}

**Binomial Foundation**: Under $H_0$: median $= \eta_0$, each observation has 50% chance of being above/below $\eta_0$

**Davis Example** ($H_0$: $\eta = 57$ kg):

::: cle8
```{r}
#| echo: true
small_sample
above <- sum(small_sample > 57)  
above
n <- length(small_sample - 57)
n
```

:::

## **Exact Binomial Formula**: {.font60}

$$
\begin{aligned}
\text{p-value} &= 2 \times P(X \geq 12) \\
&= 2 \times \sum_{k=12}^{15} \binom{15}{k} (0.5)^{15} \\
&= 2 \times (0.01389 + 0.00320 + 0.00046 + 0.00003) \\
&= 0.03516
\end{aligned}
$$

**R Calculation**:

```{r}
#| echo: true
2 * pbinom(11, 15, 0.5, lower.tail=FALSE)  # Matches SIGN.test()
```

```r
SIGN.test(small_sample, md=57)
    One-sample Sign-Test

data:  small_sample
s = 12, p-value = 0.03516
alternative hypothesis: true median is not equal to 57
95 percent confidence interval:
 58.17817 75.10916

```

